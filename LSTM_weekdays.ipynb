{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import plotly.express as px\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "\n",
    "# set plotly parameters\n",
    "import plotly.io as pio\n",
    "pio.renderers.default='notebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hanne\\AppData\\Local\\Temp\\ipykernel_15356\\3011639115.py:1: DtypeWarning:\n",
      "\n",
      "Columns (3,7,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../../Data/csv/1TF_BQ_Accidents.csv\", header=None)\n",
    "df = df.rename({19: 'date'}, axis=1)\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "df = df.groupby('date').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dow'] = df['date'].apply(lambda x: x.weekday())\n",
    "df['day'] = df['date'].dt.day\n",
    "df['month'] = df['date'].dt.month\n",
    "df['year'] = df['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data, col, max_val):\n",
    "    data[col + '_sin'] = np.sin(2 * np.pi * data[col]/max_val)\n",
    "    data[col + '_cos'] = np.cos(2 * np.pi * data[col]/max_val)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = encode(df,'dow', 6)\n",
    "df = encode(df,'month', 12)\n",
    "df = encode(df,'day', 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "df['count'] = sc.fit_transform(df['count'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=(['date', 'dow','day','month','year']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lookback(data, n_in=1, n_out=1):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list() \n",
    "    #input sequence (t-n, ...., t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    #forecast sequence\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    \n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    agg.dropna(inplace=True)\n",
    "\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reframed = create_lookback(df,1,1)\n",
    "reframed.drop(reframed.columns[[8,9,10,11,12,13]],axis=1,inplace=True)\n",
    "values = reframed.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = values[:, :-1]\n",
    "y = values[:, -1]\n",
    "train_X, test_X,train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 0,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1752, 1, 7) (1752,) (438, 1, 7) (438,)\n"
     ]
    }
   ],
   "source": [
    "train_X = train_X.reshape((train_X.shape[0],1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0],1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanne\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning:\n",
      "\n",
      "Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(15, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.6924 - val_loss: 0.7005\n",
      "Epoch 2/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6604 - val_loss: 0.6710\n",
      "Epoch 3/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6375 - val_loss: 0.6489\n",
      "Epoch 4/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6192 - val_loss: 0.6375\n",
      "Epoch 5/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.6079 - val_loss: 0.6320\n",
      "Epoch 6/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6023 - val_loss: 0.6286\n",
      "Epoch 7/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5994 - val_loss: 0.6273\n",
      "Epoch 8/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5971 - val_loss: 0.6263\n",
      "Epoch 9/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5947 - val_loss: 0.6246\n",
      "Epoch 10/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5924 - val_loss: 0.6228\n",
      "Epoch 11/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5901 - val_loss: 0.6205\n",
      "Epoch 12/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5877 - val_loss: 0.6181\n",
      "Epoch 13/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5854 - val_loss: 0.6154\n",
      "Epoch 14/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5829 - val_loss: 0.6120\n",
      "Epoch 15/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5798 - val_loss: 0.6085\n",
      "Epoch 16/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5767 - val_loss: 0.6051\n",
      "Epoch 17/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5738 - val_loss: 0.6016\n",
      "Epoch 18/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5712 - val_loss: 0.5976\n",
      "Epoch 19/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5683 - val_loss: 0.5934\n",
      "Epoch 20/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5652 - val_loss: 0.5888\n",
      "Epoch 21/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5622 - val_loss: 0.5846\n",
      "Epoch 22/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5591 - val_loss: 0.5806\n",
      "Epoch 23/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5563 - val_loss: 0.5769\n",
      "Epoch 24/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5538 - val_loss: 0.5735\n",
      "Epoch 25/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5515 - val_loss: 0.5710\n",
      "Epoch 26/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5500 - val_loss: 0.5687\n",
      "Epoch 27/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5481 - val_loss: 0.5670\n",
      "Epoch 28/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5467 - val_loss: 0.5657\n",
      "Epoch 29/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5455 - val_loss: 0.5639\n",
      "Epoch 30/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5444 - val_loss: 0.5623\n",
      "Epoch 31/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5431 - val_loss: 0.5610\n",
      "Epoch 32/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5421 - val_loss: 0.5599\n",
      "Epoch 33/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5411 - val_loss: 0.5591\n",
      "Epoch 34/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5407 - val_loss: 0.5582\n",
      "Epoch 35/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5402 - val_loss: 0.5574\n",
      "Epoch 36/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5395 - val_loss: 0.5576\n",
      "Epoch 37/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5390 - val_loss: 0.5571\n",
      "Epoch 38/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5385 - val_loss: 0.5565\n",
      "Epoch 39/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5379 - val_loss: 0.5560\n",
      "Epoch 40/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5374 - val_loss: 0.5558\n",
      "Epoch 41/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5370 - val_loss: 0.5552\n",
      "Epoch 42/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5365 - val_loss: 0.5550\n",
      "Epoch 43/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5360 - val_loss: 0.5546\n",
      "Epoch 44/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5356 - val_loss: 0.5543\n",
      "Epoch 45/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5352 - val_loss: 0.5539\n",
      "Epoch 46/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5345 - val_loss: 0.5538\n",
      "Epoch 47/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5342 - val_loss: 0.5537\n",
      "Epoch 48/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5340 - val_loss: 0.5535\n",
      "Epoch 49/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5335 - val_loss: 0.5534\n",
      "Epoch 50/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5331 - val_loss: 0.5530\n",
      "Epoch 51/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5326 - val_loss: 0.5530\n",
      "Epoch 52/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5325 - val_loss: 0.5526\n",
      "Epoch 53/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5320 - val_loss: 0.5522\n",
      "Epoch 54/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5317 - val_loss: 0.5520\n",
      "Epoch 55/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5314 - val_loss: 0.5516\n",
      "Epoch 56/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5310 - val_loss: 0.5517\n",
      "Epoch 57/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5307 - val_loss: 0.5513\n",
      "Epoch 58/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5305 - val_loss: 0.5511\n",
      "Epoch 59/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5301 - val_loss: 0.5511\n",
      "Epoch 60/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5300 - val_loss: 0.5505\n",
      "Epoch 61/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5293 - val_loss: 0.5504\n",
      "Epoch 62/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5291 - val_loss: 0.5503\n",
      "Epoch 63/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5290 - val_loss: 0.5500\n",
      "Epoch 64/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5287 - val_loss: 0.5499\n",
      "Epoch 65/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5284 - val_loss: 0.5498\n",
      "Epoch 66/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5280 - val_loss: 0.5495\n",
      "Epoch 67/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5275 - val_loss: 0.5492\n",
      "Epoch 68/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5273 - val_loss: 0.5490\n",
      "Epoch 69/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5268 - val_loss: 0.5489\n",
      "Epoch 70/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5269 - val_loss: 0.5488\n",
      "Epoch 71/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5265 - val_loss: 0.5483\n",
      "Epoch 72/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5260 - val_loss: 0.5482\n",
      "Epoch 73/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5258 - val_loss: 0.5479\n",
      "Epoch 74/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5252 - val_loss: 0.5483\n",
      "Epoch 75/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5258 - val_loss: 0.5477\n",
      "Epoch 76/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5248 - val_loss: 0.5475\n",
      "Epoch 77/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5246 - val_loss: 0.5477\n",
      "Epoch 78/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5246 - val_loss: 0.5472\n",
      "Epoch 79/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.5242 - val_loss: 0.5473\n",
      "Epoch 80/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5241 - val_loss: 0.5471\n",
      "Epoch 81/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5238 - val_loss: 0.5470\n",
      "Epoch 82/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.5235 - val_loss: 0.5469\n",
      "Epoch 83/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5233 - val_loss: 0.5469\n",
      "Epoch 84/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5233 - val_loss: 0.5469\n",
      "Epoch 85/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5229 - val_loss: 0.5469\n",
      "Epoch 86/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5227 - val_loss: 0.5467\n",
      "Epoch 87/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5225 - val_loss: 0.5465\n",
      "Epoch 88/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5222 - val_loss: 0.5465\n",
      "Epoch 89/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5221 - val_loss: 0.5464\n",
      "Epoch 90/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5218 - val_loss: 0.5463\n",
      "Epoch 91/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5216 - val_loss: 0.5462\n",
      "Epoch 92/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5212 - val_loss: 0.5463\n",
      "Epoch 93/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5210 - val_loss: 0.5464\n",
      "Epoch 94/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5210 - val_loss: 0.5462\n",
      "Epoch 95/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5206 - val_loss: 0.5462\n",
      "Epoch 96/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5204 - val_loss: 0.5462\n",
      "Epoch 97/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5204 - val_loss: 0.5463\n",
      "Epoch 98/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5201 - val_loss: 0.5459\n",
      "Epoch 99/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5198 - val_loss: 0.5461\n",
      "Epoch 100/100\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5198 - val_loss: 0.5459\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_X, train_y, epochs=100, batch_size=28, validation_data=(test_X, test_y),verbose=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for forecast\n",
    "inv_yhat = np.concatenate((y_pred, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = sc.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = sc.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 19.730\n"
     ]
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inv_ypred = np.concatenate((y_pred, test_X[:, 1:]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = pd.DataFrame()\n",
    "#y_pred = y_pred.ravel().tolist()\n",
    "chart['predicted'] = inv_yhat\n",
    "chart['actual'] = inv_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"11c63f18-4ae4-41e4-a0a0-8d028679c9fe\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"11c63f18-4ae4-41e4-a0a0-8d028679c9fe\")) {                    Plotly.newPlot(                        \"11c63f18-4ae4-41e4-a0a0-8d028679c9fe\",                        [{\"hovertemplate\":\"variable=predicted\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"predicted\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"predicted\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437],\"xaxis\":\"x\",\"y\":[127.19846670455651,113.83960186440916,135.43428224777645,107.46468989991217,79.71918750268563,120.52425648421963,113.51423243600337,126.98172301328795,115.67878859281261,137.4317578825967,102.39486198700399,79.50516194397788,96.35174680557772,85.9387336318927,96.24204576325161,104.82198593251802,116.13324110768997,81.62448724656852,76.51704812851752,95.93456738869467,112.07173541642764,107.96616710374454,125.21519239968461,96.4801760799437,85.61828189936236,75.73670346743421,99.15161417669677,103.76209511075437,119.57716318546493,115.69874977509222,129.96617614472564,92.39131523866195,80.31545916472092,100.28643866938978,120.95504398783342,107.3245210475233,104.11669234644143,123.48000328161001,89.07762332253114,75.72252536938808,79.21597122502925,116.93356852353352,118.85619262879302,101.91328000344312,117.59665015811512,79.74809960500983,63.43867697877713,87.07754239581803,109.26765560360798,119.9504965354444,103.61200208755969,121.03491858654046,89.58496575196557,66.8123607190054,89.80886403940991,100.67929967775906,95.8202104242486,101.51933539277701,121.85504622076961,89.80418364082153,66.8266914838376,95.6184301522926,98.1387547334314,106.99275454889657,112.9879518576982,113.83005853085773,53.144471753092056,28.62592040161438,66.17322453793571,91.45037797914257,97.32917391610196,80.75900430150169,87.47927923540503,63.74509249380709,54.65955021349646,80.39772498993597,84.69189320375861,89.76371200771675,72.75370730815061,98.52574092266755,58.183272216007,60.188022755068175,79.32961339362637,97.96109586553254,107.85122560804416,96.79663234014603,98.07563951490724,86.96594048606309,64.45066195872266,81.7906418113115,111.95586381492731,99.60495436054106,84.2087127823533,99.67870465645063,79.3316511633362,49.04940426021653,66.3074883386044,104.72220989070853,72.98127706585797,61.72592158114796,105.83472014131043,78.00661298200953,59.523301611957834,79.07462667244545,85.96441898893943,80.65564390906255,93.59330025671169,88.17964890277523,77.01889704278554,63.769900846544665,79.7070488337709,106.23062618829331,102.79595787500271,108.59011625844269,110.98597089326707,77.76223660246096,65.21499817974848,82.36853703868351,93.1486972386687,116.07744803506505,95.41704731180688,100.63680821744038,75.80231367817254,69.17226398513013,78.75051010733844,99.00863312328583,104.46900538831288,114.03306553022252,111.79994290311629,78.85237536092697,67.59384208387632,102.80617368915259,98.83264866362599,57.11681838186362,72.00127743701725,105.39717007987097,79.62659177808654,67.74022629982228,74.27294261963245,108.6052634586961,107.92672597144576,103.4272732021291,120.83425634987924,85.24437107067033,68.04481976994884,95.05343111979015,108.02575361411917,82.3836062461223,100.26004090191265,102.33235116093627,95.47619822401471,79.47810175614566,86.27553813445999,103.54485774156345,119.11965567544442,112.4291200655268,117.36221703272064,87.42999690337983,82.80956815175877,71.5456400951262,97.12105714281296,77.52039415967695,110.97131073324967,100.95996968170974,89.25251474193385,63.146937388269656,97.4793359090064,89.92632038852659,71.48019250770346,54.72461281511082,79.83595436213258,60.887173577282134,59.6975076902448,93.42782895880748,100.536865611189,109.1360020730969,74.67200696075231,115.43244247983932,90.30127084484339,91.2294052519575,101.1515138116014,96.69858500077564,114.93033967406836,123.48142208706757,125.17731776136472,96.79687793454103,82.62983619958445,111.6034781733614,121.71872971559682,119.82646804712925,117.91756238013608,125.5199733844506,98.0763387536788,88.84954163326394,110.92173717273582,125.32035824281127,130.02841109195438,126.3852140539656,130.0809682924831,103.65388920727887,90.73063871328881,116.39834864113489,130.54171997170775,116.86264982313583,128.37297211596774,133.0478083231879,102.10131653095358,101.54730950704871,123.4473392270758,123.76391538048784,130.85589826092541,127.04567712128166,124.74552464826874,101.08777293928173,91.89659893323366,126.73521593642064,117.86660818086118,122.73760627339647,98.72959422704211,96.89575622927153,89.75179819042715,89.81190907802352,94.33704513010993,112.16404820964601,119.71513579338233,107.77954606284845,134.923050963851,108.52623267586647,96.87121504340959,87.72961874642935,72.76656284719128,126.77862640515742,128.20322324406558,133.6770443950648,97.7818293811136,92.13160746306372,101.19513751601222,126.27581170752529,130.88345461581238,129.84879198044803,133.88529184780384,108.1914775589601,95.47739632640109,109.55165482211918,130.6950107003021,119.0636186678461,128.33705227627826,136.55722279276847,103.10991338687222,93.8625156882972,106.67063841651367,117.9006960191177,132.24592934815976,119.57507563310747,120.47871531816412,103.00836342338538,92.60587388655478,111.27420329624873,113.9971108426797,113.96379297603991,88.2003767378284,108.44742010697561,106.59282315999708,83.88361383966632,99.22032636495193,99.65398985360507,106.741143920936,90.01587190422288,105.19868915288691,89.00419059842793,93.31642286079992,110.92590729918595,95.99667497531655,99.09396566330898,91.40320975022023,88.18980456289255,87.23687507841356,82.33322620671677,92.89654066100574,76.01637076589047,80.87116626604251,91.54098156812552,97.87889247605473,92.69290847455775,77.46663719734026,80.7880906430926,96.14072023653452,120.7444003303216,102.16515489429155,105.82729174057266,99.25695104396081,82.66548223471192,95.43775315952402,105.76280412853846,113.7346268547651,101.54108958008224,107.92627875732785,102.31011366709359,87.32498372703925,104.70095518930123,77.33304048414988,110.02075007308726,90.63779241602995,115.08560345493062,78.47347299209885,72.05675356011889,78.35189049120412,118.02769487207502,115.78231990567528,107.87103246411611,118.41416586276509,95.49237343594176,77.39722525174429,109.61713144941969,113.24505434140359,92.92103206422004,96.77834551424851,132.76946026489395,106.86950101046293,87.3772372534174,106.06316482904995,127.62674018446478,125.34626845148314,118.07852627415242,126.96345941929265,103.94329855502168,86.66190458159004,117.2322295614837,124.51721312911164,121.39514416539791,126.2546789736047,119.57929720162683,100.49582106278102,85.50202282292128,106.4083377946845,124.87539098172977,108.5250304249261,107.24230002669113,137.37908784140004,89.07827049695037,77.86206740518286,111.33382382476591,116.41956268671329,118.18326896477419,112.76111888317583,128.96597969573983,102.76487815322946,75.96203632484122,86.2405069150308,114.61997307623786,131.25393044181766,117.32302481366004,137.87961585608417,103.67586575707686,85.01031629339786,122.49062792079823,113.68047826893368,124.61676017074201,122.23980800722424,126.60581092216103,99.5648328653913,88.11991055532532,109.8530970506505,123.35406148020412,121.39569011510031,124.92075956794014,128.8459006308036,105.29861869119327,80.93792977478435,97.45026263536049,125.73339989196515,125.13083238442576,124.71603672665358,131.19223314718334,95.8797595976375,80.12774539470928,112.2978764121479,90.52823740280357,73.57203944822177,100.6402168768094,112.36583304501139,81.37966448261284,66.21954231329431,91.56375878883962,111.50479569037826,115.55360846591552,122.90389525128805,132.780631491023,68.81420063260157,84.70744032461468,111.35344150677685,111.53413841260449,122.51340182266915,122.21498637911397,129.0184174179142,100.56693598978148,64.76270623177842,97.11163598417593,122.53238228679038,112.19606757889336,121.7021554127779,121.85425301725064,91.01613224093981,66.9864240870358,94.4877521392921,114.43054512372602,106.39374898979538,109.03219612596143,115.0104864179158,76.72797554712085,58.00162529132035,77.00926244104679,112.06466213190966,117.72985192896762,119.29069557734188,121.63349020689643,85.5419335715294,65.10559251446499,88.16359399891329,113.96917282082755,110.69103027851672,117.45978936266154,119.24515773012955,84.3833221000861,62.33286830225755,113.73359469453749,103.11721110815996,121.66170701157533,113.38987538221384,123.3529214575733,73.25265555348318,54.71008623853124,66.23173574312145,66.95409855450552,80.09556423185713,79.91462919903164,56.81480033404132,62.07832298721896],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hovertemplate\":\"variable=actual\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"actual\",\"line\":{\"color\":\"#EF553B\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"actual\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437],\"xaxis\":\"x\",\"y\":[108.0,141.0,149.0,98.0,114.0,102.0,135.0,116.0,169.0,145.0,105.0,81.0,63.0,83.0,97.0,95.0,93.0,101.0,66.0,102.0,92.0,132.0,63.0,99.0,90.0,66.0,76.0,120.0,109.0,139.0,117.0,103.0,76.0,126.0,98.0,96.0,114.0,125.0,109.0,57.0,128.0,120.0,100.0,111.0,111.0,83.0,59.0,111.0,128.0,92.0,109.0,133.0,87.0,55.0,79.0,76.0,88.0,122.0,130.0,85.0,72.0,78.0,102.0,113.0,104.0,64.0,26.0,42.0,77.0,92.0,78.0,76.0,79.0,68.0,60.0,65.0,81.0,66.0,84.0,75.0,82.0,47.0,84.0,107.0,89.0,82.0,138.0,87.0,53.0,124.0,95.0,77.0,86.0,112.0,60.0,43.0,100.0,66.0,62.0,103.0,118.0,79.0,62.0,71.0,78.0,97.0,77.0,104.0,84.0,58.0,107.0,102.0,114.0,108.0,114.0,91.0,60.0,78.0,133.0,93.0,89.0,100.0,89.0,58.0,85.0,106.0,129.0,115.0,107.0,86.0,95.0,89.0,55.0,75.0,91.0,94.0,81.0,55.0,105.0,109.0,105.0,128.0,124.0,89.0,82.0,103.0,77.0,99.0,88.0,163.0,98.0,67.0,87.0,127.0,118.0,124.0,117.0,105.0,55.0,82.0,76.0,118.0,87.0,96.0,63.0,82.0,74.0,69.0,53.0,65.0,65.0,68.0,80.0,89.0,108.0,71.0,106.0,121.0,121.0,84.0,78.0,112.0,151.0,135.0,139.0,92.0,95.0,115.0,121.0,128.0,152.0,148.0,104.0,98.0,128.0,141.0,143.0,122.0,141.0,111.0,111.0,161.0,118.0,156.0,161.0,153.0,153.0,122.0,120.0,152.0,159.0,117.0,138.0,107.0,118.0,102.0,123.0,95.0,79.0,93.0,99.0,77.0,99.0,121.0,114.0,139.0,145.0,122.0,74.0,56.0,138.0,150.0,133.0,117.0,118.0,90.0,136.0,155.0,170.0,145.0,158.0,119.0,93.0,130.0,118.0,158.0,162.0,129.0,111.0,92.0,109.0,149.0,135.0,112.0,120.0,113.0,108.0,113.0,119.0,85.0,95.0,135.0,97.0,89.0,89.0,107.0,86.0,93.0,99.0,116.0,99.0,79.0,92.0,84.0,70.0,93.0,93.0,77.0,60.0,74.0,88.0,83.0,100.0,84.0,66.0,86.0,131.0,105.0,90.0,109.0,94.0,82.0,98.0,118.0,100.0,92.0,124.0,103.0,91.0,50.0,108.0,80.0,101.0,79.0,78.0,57.0,107.0,116.0,110.0,108.0,107.0,89.0,103.0,110.0,89.0,97.0,130.0,135.0,109.0,97.0,149.0,139.0,124.0,113.0,122.0,100.0,113.0,137.0,129.0,145.0,103.0,118.0,96.0,85.0,121.0,100.0,102.0,142.0,95.0,91.0,99.0,109.0,120.0,117.0,124.0,126.0,94.0,62.0,112.0,158.0,116.0,137.0,129.0,103.0,130.0,100.0,135.0,125.0,110.0,121.0,104.0,87.0,124.0,122.0,135.0,115.0,139.0,98.0,74.0,129.0,130.0,134.0,127.0,122.0,107.0,108.0,72.0,52.0,93.0,92.0,94.0,76.0,60.0,102.0,108.0,123.0,139.0,68.0,111.0,96.0,96.0,132.0,127.0,130.0,142.0,73.0,69.0,133.0,105.0,126.0,109.0,129.0,88.0,78.0,118.0,100.0,106.0,108.0,104.0,70.0,44.0,124.0,121.0,121.0,110.0,122.0,84.0,52.0,127.0,104.0,120.0,111.0,115.0,76.0,118.0,87.0,140.0,113.0,136.0,95.0,69.0,41.00000000000001,43.0,70.0,77.0,48.0,77.0,38.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"margin\":{\"t\":60}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('11c63f18-4ae4-41e4-a0a0-8d028679c9fe');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = px.line(chart)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
